{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb575eba-e0f1-4b2b-9615-563a605e4e71",
   "metadata": {},
   "source": [
    "# üßæ Rapport Final ‚Äî Mini Data Warehouse TP2\n",
    "\n",
    "## R√©alis√© par : CAKPOSSE Eriyomi Phest√®ce Chancelle-H√©l√®ne\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cd5fa2-3e7b-456b-99e4-96523c125c94",
   "metadata": {},
   "source": [
    "## üéØ Objectif du projet\n",
    "\n",
    "Ce TP vise √† construire un mini Data Warehouse simul√©, en suivant toutes les √©tapes d‚Äôun pipeline ETL : g√©n√©ration de donn√©es, nettoyage, mod√©lisation en √©toile, automatisation, visualisation et requ√™tage SQL.  \n",
    "L‚Äôobjectif est de comprendre les fondements d‚Äôun entrep√¥t de donn√©es et de manipuler des outils concrets comme pandas, DuckDB et matplotlib.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e37d6a-65ab-45be-8071-7d75025826c9",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Architecture du projet\n",
    "\n",
    "Le projet est structur√© en plusieurs dossiers :\n",
    "\n",
    "- `data/raw` : donn√©es simul√©es (production, pannes)\n",
    "- `data/staging` : donn√©es nettoy√©es et enrichies\n",
    "- `data/dim` : dimensions (date, machine, produit)\n",
    "- `data/fact` : faits (production, downtime)\n",
    "- `src/etl` : scripts Python pour chaque √©tape\n",
    "- `notebooks` : exploration, visualisation, requ√™tes SQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e835e183-75a3-43cd-9cb0-2c814800e101",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Pipeline ETL\n",
    "\n",
    "### a. G√©n√©ration des donn√©es (`generate_raw.py`)\n",
    "- Simulation de 90 jours de production pour 3 machines et 3 produits\n",
    "- Donn√©es de production et de pannes g√©n√©r√©es al√©atoirement\n",
    "\n",
    "### b. Nettoyage et enrichissement (`staging.py`)\n",
    "- Calcul des unit√©s bonnes, performance th√©orique, disponibilit√©\n",
    "- Agr√©gation des pannes par jour et machine\n",
    "\n",
    "### c. Mod√©lisation en √©toile (`build_dimensions.py`)\n",
    "- Cr√©ation des dimensions avec cl√©s substitutives\n",
    "- Enrichissement de la dimension date (ann√©e, mois, jour, jour de semaine)\n",
    "\n",
    "### d. Construction des faits (`build_facts.py`)\n",
    "- Jointures avec les dimensions\n",
    "- Cr√©ation des tables de faits pr√™tes pour l‚Äôanalyse\n",
    "\n",
    "### e. Orchestration (`run_all.py`)\n",
    "- Ex√©cution automatique de toutes les √©tapes du pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5627ba-edbc-4779-9f3d-ec6de9130c2b",
   "metadata": {},
   "source": [
    "## üìä Visualisation des indicateurs\n",
    "\n",
    "### a. OEE mensuel par machine (`visualisation.ipynb`)\n",
    "- Calcul de l‚ÄôOEE : disponibilit√© √ó performance √ó qualit√©\n",
    "- Trac√© de l‚Äô√©volution mensuelle par machine\n",
    "\n",
    "### b. Exploration des donn√©es (`traitements.ipynb`)\n",
    "- V√©rification des donn√©es √† chaque √©tape\n",
    "- Statistiques descriptives et contr√¥les qualit√©\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a487ff18-1138-4dd1-a99c-24e36bd4909c",
   "metadata": {},
   "source": [
    "## üß† Requ√™tes SQL analytiques\n",
    "\n",
    "### a. Top produits les plus performants (`requetes_duckdb.ipynb`)\n",
    "- Requ√™te SQL pour identifier les produits avec la meilleure performance moyenne\n",
    "\n",
    "### b. Requ√™te OEE par machine et mois\n",
    "- Agr√©gation SQL pour reproduire la visualisation en mode analytique\n",
    "\n",
    "### c. Requ√™te personnalis√©e (optionnelle)\n",
    "- Possibilit√© d‚Äôajouter des requ√™tes pour d√©tecter les machines en sous-performance ou analyser les pannes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e0c910-c37c-4bdc-a8d9-6cef92854601",
   "metadata": {},
   "source": [
    "## üìå R√©sultats et observations\n",
    "\n",
    "- Les machines ont des performances variables selon les mois\n",
    "- Le produit P1 est le plus performant dans cette simulation\n",
    "- Le pipeline est enti√®rement automatis√© et reproductible\n",
    "- DuckDB permet des requ√™tes SQL rapides directement sur les fichiers CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dec50b-1635-4e38-9ad3-bfa9cf48eee4",
   "metadata": {},
   "source": [
    "## üß™ Limites et extensions possibles\n",
    "\n",
    "- Simulation simple : pas de saisonnalit√© ni de logique m√©tier\n",
    "- Possibilit√© d‚Äôajouter des dimensions suppl√©mentaires (op√©rateurs, lignes de production)\n",
    "- Int√©gration future avec une base SQL ou un outil BI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a0c8f8-0fda-4e82-8183-bd86228e2019",
   "metadata": {},
   "source": [
    "## üë©‚Äçüíª Conclusion\n",
    "\n",
    "Ce projet m‚Äôa permis de consolider mes comp√©tences en :\n",
    "\n",
    "- Structuration de projet analytique\n",
    "- Manipulation de donn√©es avec pandas\n",
    "- Mod√©lisation en √©toile\n",
    "- Automatisation avec Python\n",
    "- Visualisation et requ√™tage SQL\n",
    "\n",
    "Il constitue une base solide pour aborder des projets industriels plus complexes en Big Data et Intelligence Artificielle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35eeb25-9b9d-42a3-863a-66ffb766db8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
